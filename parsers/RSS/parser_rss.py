import aiohttp
import asyncio
import feedparser
import xml.etree.ElementTree as ET

import datetime
import time

from dateutil import parser as dateparser
from core.redis_client import redis_client
from parsers.RSS import RSS_URLS
from parsers.RSS.ria_rss import parse_ria
from parsers.RSS.tass_rss import parse_tass
from producer import send_raw


async def fetch(session, url: str) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç RSS –ø–æ URL.
    """
    async with session.get(url, timeout=15) as r:
        return await r.text()


async def rss_parser():
    print('RSS parser')
    async with aiohttp.ClientSession() as session:
        while True:
            # —Å–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á ‚Äî –∫–∞–∂–¥—ã–π RSS –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
            tasks = [process_rss(session, rss) for rss in RSS_URLS]
            await asyncio.gather(*tasks)

            # –∂–¥—ë–º 5 –º–∏–Ω—É—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π —Ü–∏–∫–ª
            await asyncio.sleep(120)

async def process_rss(session, rss):
    rss_url = rss[0]
    rss_id = rss[1]
    rss_name = rss[2]

    try:
        # 1. –°–∫–∞—á–∏–≤–∞–µ–º XML
        data = await fetch(session, rss_url)
        feed = feedparser.parse(data)
        root = ET.fromstring(data)

        # 2. –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        for entry in feed.entries:
            url = entry.link
            redis_key = f"seen_urls:{rss_id}"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
            added = await redis_client.sadd(redis_key, url)
            if added == 0:
                print(f"‚ö†Ô∏è [{rss_name}] –≤—Å—Ç—Ä–µ—á–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –Ω–æ–≤–æ—Å—Ç—å ‚Üí –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É")
                break

            # 3. –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            if rss_id == 1: content = await parse_ria(url)  # –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏
            elif rss_id == 2: content = await parse_tass(url)  # –¢–ê–°–°
            elif rss_id == 5: # RBC
                ns = {"rbc": "https://www.rbc.ru"}

                guid = entry.get("guid")
                item = None
                for it in root.findall(".//item"):
                    if it.findtext("guid") == guid or it.findtext("link") == url:
                        item = it
                        break

                if item is not None:
                    full = item.find("rbc:full-text", ns)
                    if full is not None and full.text:
                        content = full.text
                    else:
                        content = entry.get("description", "")
            elif rss_id == 6:  # –í–∑–≥–ª—è–¥
                ns = {"yandex": "http://news.yandex.ru"}

                # –∏—â–µ–º item —Å —Ç–∞–∫–∏–º guid –∏–ª–∏ link
                guid = entry.get("guid")
                item = None
                for it in root.findall(".//item"):
                    if it.findtext("guid") == guid or it.findtext("link") == url:
                        item = it
                        break
                if item is not None:
                    full = item.find("yandex:full-text", ns)
                    if full is not None and full.text:
                        content = full.text
                    else:
                        content = entry.get("description", "")

                else:
                    content = entry.get("description", "")
            elif rss_id == 7: #–í–∑–≥–ª—è–¥
                root = ET.fromstring(data)
                ns = {"content": "http://purl.org/rss/1.0/modules/content/"}

                guid = entry.get("guid")
                item = None
                for it in root.findall(".//item"):
                    if it.findtext("guid") == guid or it.findtext("link") == url:
                        item = it
                        break

                if item is not None:
                    full = item.find("content:encoded", ns)
                    if full is not None and full.text:
                        content = full.text
                    else:
                        content = entry.get("description", "")
                else:
                    content = entry.get("description", "")
            else:
                content = entry.get("description", "")

            # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç –Ω–æ–≤–æ—Å—Ç–∏
            news = {
                "title": entry.title,
                "description": content,
                "news_date": normalize_date_str(entry),
                "url": url,
                "source": rss_name,
                "flag": "raw",
                "name": "rss_parser"
            }

            # 5. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Kafka
            await send_raw(news)
            print(f"üì§ [{rss_name}] –Ω–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞: {entry.title[:60]}")

    except Exception as e:
        print(f"[RSS error] {rss_name} ({rss_url}): {e}")



def normalize_date_str(entry) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –¥–∞—Ç—É –∏–∑ RSS –∫ —Å—Ç—Ä–æ–∫–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO-8601 (YYYY-MM-DDTHH:MM:SS).
    """
    # 1. –ï—Å–ª–∏ –µ—Å—Ç—å published_parsed (struct_time)
    if entry.get("published_parsed"):
        dt = datetime.datetime(*entry.published_parsed[:6])
        return dt.isoformat()

    # 2. –ï—Å–ª–∏ –µ—Å—Ç—å published (—Å—Ç—Ä–æ–∫–∞)
    if entry.get("published"):
        try:
            dt = dateparser.parse(entry.published)
            return dt.replace(tzinfo=None).isoformat()
        except Exception:
            pass

    # 3. fallback ‚Üí —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
    return datetime.datetime.utcnow().isoformat()